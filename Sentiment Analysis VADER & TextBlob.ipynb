{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are trying two sentiment analysis solutions for Python. The first is TextBlob, and the second is going to be Vader Sentiment.\n",
    "\n",
    "### We start with TextBlob\n",
    "\n",
    "With TextBlob, we get a polarity and a subjectivity metric. The polarity is the sentiment itself, ranging from a -1 to a +1. The subjectivity is a measure of the sentiment being objective to subjective, and goes from 0 to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis = TextBlob('TextBlob sure looks like it has some interesting features!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dir(analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"¡TextBlob seguro parece tener algunas características interesantes!\")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis.translate(to = 'es')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"TextBlob semble avoir des fonctionnalités intéressantes!\")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis.translate(to = 'fr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('TextBlob', 'NNP'),\n",
       " ('sure', 'JJ'),\n",
       " ('looks', 'VBZ'),\n",
       " ('like', 'IN'),\n",
       " ('it', 'PRP'),\n",
       " ('has', 'VBZ'),\n",
       " ('some', 'DT'),\n",
       " ('interesting', 'JJ'),\n",
       " ('features', 'NNS')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis.tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=0.5625, subjectivity=0.6944444444444444)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis.sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this sentence is fairly positive, but also highly subjective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive accuracy = 71.11236165822548% via 5331 samples\n",
      "Negative accuracy = 55.861939598574374% via 5331 samples\n"
     ]
    }
   ],
   "source": [
    "# Now, let's test this on a bit more data using the positive.txt and negative.txt datasets.\n",
    "\n",
    "pos_count = 0\n",
    "pos_correct = 0\n",
    "with open('positive.txt', 'r') as f:\n",
    "    for line in f.read().split('\\n'):\n",
    "        analysis = TextBlob(line)\n",
    "        if analysis.sentiment.polarity > 0:\n",
    "            pos_correct += 1\n",
    "        pos_count += 1\n",
    "\n",
    "neg_count = 0\n",
    "neg_correct = 0\n",
    "\n",
    "with open('negative.txt', 'r') as f:\n",
    "    for line in f.read().split('\\n'):\n",
    "        analysis = TextBlob(line)\n",
    "        if analysis.sentiment.polarity <= 0:\n",
    "            neg_correct += 1\n",
    "        neg_count += 1\n",
    "        \n",
    "# with > 0 and <= 0\n",
    "\n",
    "print('Positive accuracy = {}% via {} samples'.format(pos_correct/pos_count*100.0, pos_count))\n",
    "print('Negative accuracy = {}% via {} samples'.format(neg_correct/neg_count*100.0, neg_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like our positive accuracy is decent, but the negative sentiment accuracy isn't all that good. It could be the case that this classifier is biased across the board, so our \"zero\" could be moved a bit, let's say 0.2, so we change:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive accuracy = 18.574297188755022% via 996 samples\n",
      "Negative accuracy = 87.27969348659003% via 1305 samples\n"
     ]
    }
   ],
   "source": [
    "# What if we play with the subjectivity though? Maybe we can only look at reviews that we feel are more objective?\n",
    "\n",
    "pos_count = 0\n",
    "pos_correct = 0\n",
    "with open('positive.txt', 'r') as f:\n",
    "    for line in f.read().split('\\n'):\n",
    "        analysis = TextBlob(line)\n",
    "        \n",
    "        if analysis.sentiment.subjectivity < 0.3:\n",
    "            if analysis.sentiment.polarity > 0.1:\n",
    "                pos_correct += 1\n",
    "            pos_count += 1\n",
    "\n",
    "neg_count = 0\n",
    "neg_correct = 0\n",
    "\n",
    "with open('negative.txt', 'r') as f:\n",
    "    for line in f.read().split('\\n'):\n",
    "        analysis = TextBlob(line)\n",
    "        \n",
    "        if analysis.sentiment.subjectivity < 0.3:\n",
    "            if analysis.sentiment.polarity <= 0.1:\n",
    "                neg_correct += 1\n",
    "            neg_count += 1\n",
    "        \n",
    "# with > 0 and <= 0\n",
    "\n",
    "print('Positive accuracy = {}% via {} samples'.format(pos_correct/pos_count*100.0, pos_count))\n",
    "print('Negative accuracy = {}% via {} samples'.format(neg_correct/neg_count*100.0, neg_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive accuracy = 59.263092527427034% via 4831 samples\n",
      "Negative accuracy = 68.27292974286293% via 4939 samples\n"
     ]
    }
   ],
   "source": [
    "# What if we flip things around and require a high degree of subjectivity?\n",
    "\n",
    "pos_count = 0\n",
    "pos_correct = 0\n",
    "with open('positive.txt', 'r') as f:\n",
    "    for line in f.read().split('\\n'):\n",
    "        analysis = TextBlob(line)\n",
    "        \n",
    "        if analysis.sentiment.subjectivity < 0.9:\n",
    "            if analysis.sentiment.polarity > 0.1:\n",
    "                pos_correct += 1\n",
    "            pos_count += 1\n",
    "\n",
    "neg_count = 0\n",
    "neg_correct = 0\n",
    "\n",
    "with open('negative.txt', 'r') as f:\n",
    "    for line in f.read().split('\\n'):\n",
    "        analysis = TextBlob(line)\n",
    "        \n",
    "        if analysis.sentiment.subjectivity < 0.9:\n",
    "            if analysis.sentiment.polarity <= 0.1:\n",
    "                neg_correct += 1\n",
    "            neg_count += 1\n",
    "        \n",
    "# with > 0 and <= 0\n",
    "\n",
    "print('Positive accuracy = {}% via {} samples'.format(pos_correct/pos_count*100.0, pos_count))\n",
    "print('Negative accuracy = {}% via {} samples'.format(neg_correct/neg_count*100.0, neg_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let us try VADER Sentiment and see if it's better than TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.0, 'neu': 0.463, 'pos': 0.537, 'compound': 0.6996}\n"
     ]
    }
   ],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()\n",
    "vs = analyzer.polarity_scores('VADER Sentiment looks interesting, I have high hopes!')\n",
    "print(vs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vader documentation suggests:\n",
    "- positive sentiment: compound score >= 0.5\n",
    "- neutral sentiment: (compound score > -0.5) and (compound score < 0.5)\n",
    "- negative sentiment: compound score <= -0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive accuracy = 69.44288126055149% via 5331 samples\n",
      "Negative accuracy = 57.75651847683362% via 5331 samples\n"
     ]
    }
   ],
   "source": [
    "# to properly compare, we should just start with 0.\n",
    "\n",
    "pos_count = 0\n",
    "pos_correct = 0\n",
    "\n",
    "with open('positive.txt', 'r') as f:\n",
    "    for line in f.read().split('\\n'):\n",
    "        vs = analyzer.polarity_scores(line)\n",
    "        if vs ['compound'] > 0:\n",
    "            pos_correct += 1\n",
    "        pos_count += 1\n",
    "\n",
    "\n",
    "neg_count = 0\n",
    "neg_correct = 0\n",
    "\n",
    "with open('negative.txt', 'r') as f:\n",
    "    for line in f.read().split('\\n'):\n",
    "        vs = analyzer.polarity_scores(line)\n",
    "        if vs['compound'] <= 0:\n",
    "            neg_correct += 1\n",
    "        neg_count += 1\n",
    "\n",
    "print('Positive accuracy = {}% via {} samples'.format(pos_correct/pos_count*100.0, pos_count))\n",
    "print('Negative accuracy = {}% via {} samples'.format(neg_correct/neg_count*100.0, neg_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, now let's go with the 0.5 and -0.5 as suggested by the documentation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive accuracy = 87.22179585571757% via 2606 samples\n",
      "Negative accuracy = 50.0% via 1818 samples\n"
     ]
    }
   ],
   "source": [
    "pos_count = 0\n",
    "pos_correct = 0\n",
    "\n",
    "threshold = 0.5\n",
    "\n",
    "with open('positive.txt', 'r') as f:\n",
    "    for line in f.read().split('\\n'):\n",
    "        vs = analyzer.polarity_scores(line)\n",
    "        \n",
    "        if vs['compound'] >= threshold or vs['compound'] <= -threshold:\n",
    "            if vs ['compound'] > 0:\n",
    "                pos_correct += 1\n",
    "            pos_count += 1\n",
    "\n",
    "\n",
    "neg_count = 0\n",
    "neg_correct = 0\n",
    "\n",
    "with open('negative.txt', 'r') as f:\n",
    "    for line in f.read().split('\\n'):\n",
    "        vs = analyzer.polarity_scores(line)\n",
    "        \n",
    "        if vs['compound'] >= threshold or vs['compound'] <= -threshold:\n",
    "            if vs['compound'] <= -0.5:\n",
    "                neg_correct += 1\n",
    "            neg_count += 1\n",
    "\n",
    "print('Positive accuracy = {}% via {} samples'.format(pos_correct/pos_count*100.0, pos_count))\n",
    "print('Negative accuracy = {}% via {} samples'.format(neg_correct/neg_count*100.0, neg_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used a lot of samples here, and we aren't doing much different than TextBlob. Should we give up? Maybe, but what if we instead look for no conflict. So, what if we look only for signals where the opposite is lower, or non-existent? For example, to classify something as positive here, why not require the neg bit to be less than 0.1 or something like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive accuracy = 80.71428571428572% via 3920 samples\n",
      "Negative accuracy = 91.73643975245722% via 2747 samples\n"
     ]
    }
   ],
   "source": [
    "pos_count = 0\n",
    "pos_correct = 0\n",
    "\n",
    "with open(\"positive.txt\",\"r\") as f:\n",
    "    for line in f.read().split('\\n'):\n",
    "        vs = analyzer.polarity_scores(line)\n",
    "        if not vs['neg'] > 0.1:\n",
    "            if vs['pos']-vs['neg'] > 0:\n",
    "                pos_correct += 1\n",
    "            pos_count +=1\n",
    "\n",
    "\n",
    "neg_count = 0\n",
    "neg_correct = 0\n",
    "\n",
    "with open(\"negative.txt\",\"r\") as f:\n",
    "    for line in f.read().split('\\n'):\n",
    "        vs = analyzer.polarity_scores(line)\n",
    "        if not vs['pos'] > 0.1:\n",
    "            if vs['pos']-vs['neg'] <= 0:\n",
    "                neg_correct += 1\n",
    "            neg_count +=1\n",
    "\n",
    "print(\"Positive accuracy = {}% via {} samples\".format(pos_correct/pos_count*100.0, pos_count))\n",
    "print(\"Negative accuracy = {}% via {} samples\".format(neg_correct/neg_count*100.0, neg_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall the suggestion about -0.5 to 0.5 being \"neutral\" with VADER? What if we tried this with the TextBlob?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive accuracy = 100.0% via 766 samples\n",
      "Negative accuracy = 100.0% via 282 samples\n"
     ]
    }
   ],
   "source": [
    "pos_count = 0\n",
    "pos_correct = 0\n",
    "\n",
    "with open(\"positive.txt\",\"r\") as f:\n",
    "    for line in f.read().split('\\n'):\n",
    "        analysis = TextBlob(line)\n",
    "\n",
    "        if analysis.sentiment.polarity >= 0.5:\n",
    "            if analysis.sentiment.polarity > 0:\n",
    "                pos_correct += 1\n",
    "            pos_count +=1\n",
    "\n",
    "\n",
    "neg_count = 0\n",
    "neg_correct = 0\n",
    "\n",
    "with open(\"negative.txt\",\"r\") as f:\n",
    "    for line in f.read().split('\\n'):\n",
    "        analysis = TextBlob(line)\n",
    "        if analysis.sentiment.polarity <= -0.5:\n",
    "            if analysis.sentiment.polarity <= 0:\n",
    "                neg_correct += 1\n",
    "            neg_count +=1\n",
    "\n",
    "print(\"Positive accuracy = {}% via {} samples\".format(pos_correct/pos_count*100.0, pos_count))\n",
    "print(\"Negative accuracy = {}% via {} samples\".format(neg_correct/neg_count*100.0, neg_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2 is Sentiment Analysis GUI with Dash and Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
