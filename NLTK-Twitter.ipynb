{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Twitter sentiment analysis using Python and NLTK\n",
    "#### The purpose of the implementation is to be able to automatically classify a tweet as positive or negative, sentiment wise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the classifier using a list of manually classified tweets; 5 positive tweets and 5 negative tweets.\n",
    "\n",
    "Positive tweets:\n",
    "\n",
    "I love this car.\n",
    "This view is amazing.\n",
    "I feel great this morning.\n",
    "I am so excited about the concert.\n",
    "He is my best friend.\n",
    "\n",
    "Negative tweets:\n",
    "\n",
    "I do not like this car.\n",
    "This view is horrible.\n",
    "I feel tired this morning.\n",
    "I am not looking forward to the concert.\n",
    "He is my enemy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the full implementation, 600 positive tweets and 600 negative tweets are used to train the classifier. \n",
    "The tweets are stored in a Redis DB. \n",
    "Even with those numbers, it is quite a small sample. You should use a much larger set if you want good results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next is a test set so we can assess the exactitude of the trained classifier.\n",
    "\n",
    "Test tweets:\n",
    "\n",
    "I feel happy this morning. -positive.\n",
    "Larry is my friend. -positive.\n",
    "I do not like that man. -negative.\n",
    "My house is not great. -negative.\n",
    "Your song is annoying. -negative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list containing the positive tweets:\n",
    "pos_tweets = [('I love this car', 'positive'),\n",
    "              ('This view is amazing', 'positive'),\n",
    "              ('I feel great this morning', 'positive'),\n",
    "              ('I am so excited about the concert', 'positive'),\n",
    "              ('He is my best friend', 'positive')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list containing the negative tweets:\n",
    "neg_tweets = [('I do not like this car', 'negative'),\n",
    "              ('This view is horrible', 'negative'),\n",
    "              ('I feel tired this morning', 'negative'),\n",
    "              ('I am not looking forward to the concert', 'negative'),\n",
    "              ('He is my enemy', 'negative')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We take both of those lists and create a single list of tuples each containing two elements. \n",
    "# First element is an array containing the words and second element is the type of sentiment. \n",
    "# We get rid of the words smaller than 2 characters and we use lowercase for everything.\n",
    "\n",
    "tweets = []\n",
    "for (words, sentiment) in pos_tweets + neg_tweets:\n",
    "    words_filtered = [e.lower() for e in words.split() if len(e) >= 3]\n",
    "    tweets.append((words_filtered, sentiment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['love', 'this', 'car'], 'positive'),\n",
       " (['this', 'view', 'amazing'], 'positive'),\n",
       " (['feel', 'great', 'this', 'morning'], 'positive'),\n",
       " (['excited', 'about', 'the', 'concert'], 'positive'),\n",
       " (['best', 'friend'], 'positive'),\n",
       " (['not', 'like', 'this', 'car'], 'negative'),\n",
       " (['this', 'view', 'horrible'], 'negative'),\n",
       " (['feel', 'tired', 'this', 'morning'], 'negative'),\n",
       " (['not', 'looking', 'forward', 'the', 'concert'], 'negative'),\n",
       " (['enemy'], 'negative')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The list of tweets now looks like this:\n",
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, we add the list with the test tweets:\n",
    "test = [('I feel happy this morning', 'positive'),\n",
    "              ('Larry is my friend', 'positive'),\n",
    "              ('I do not like that man', 'negative'),\n",
    "              ('My house is not great', 'negative'),\n",
    "              ('Your song is annoying', 'negative')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tweets = []\n",
    "for (words, sentiment) in test:\n",
    "    words_filtered = [e.lower() for e in words.split() if len(e) >= 3]\n",
    "    test_tweets.append((words_filtered, sentiment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['feel', 'happy', 'this', 'morning'], 'positive'),\n",
       " (['larry', 'friend'], 'positive'),\n",
       " (['not', 'like', 'that', 'man'], 'negative'),\n",
       " (['house', 'not', 'great'], 'negative'),\n",
       " (['your', 'song', 'annoying'], 'negative')]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier\n",
    "The list of word features need to be extracted from the tweets. It is a list with every distinct words ordered by frequency of appearance. We use the following function to get the list plus the two helper functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "word_features = get_word_features(get_word_in_tweets(tweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_in_tweets(tweets):\n",
    "    all_words = []\n",
    "    for(words, sentiment) in tweets:\n",
    "        all_words.extend(words)\n",
    "    return all_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_features(wordlist):\n",
    "    wordlist = nltk.FreqDist(wordlist)\n",
    "    word_features = wordlist.keys()\n",
    "    return word_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['love', 'this', 'car', 'view', 'amazing', 'feel', 'great', 'morning', 'excited', 'about', 'the', 'concert', 'best', 'friend', 'not', 'like', 'horrible', 'tired', 'looking', 'forward', 'enemy'])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a classifier, we need to decide what features are relevant. To do that, we first need a feature extractor. The one we are going to use returns a dictionary indicating what words are contained in the input passed. Here, the input is the tweet. We use the word features list defined above along with the input to create the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(document):\n",
    "    document_words = set(document)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features['contains(%s)' % word] = word in document_words\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'contains(love)': True,\n",
       " 'contains(this)': True,\n",
       " 'contains(car)': True,\n",
       " 'contains(view)': False,\n",
       " 'contains(amazing)': False,\n",
       " 'contains(feel)': False,\n",
       " 'contains(great)': False,\n",
       " 'contains(morning)': False,\n",
       " 'contains(excited)': False,\n",
       " 'contains(about)': False,\n",
       " 'contains(the)': False,\n",
       " 'contains(concert)': False,\n",
       " 'contains(best)': False,\n",
       " 'contains(friend)': False,\n",
       " 'contains(not)': False,\n",
       " 'contains(like)': False,\n",
       " 'contains(horrible)': False,\n",
       " 'contains(tired)': False,\n",
       " 'contains(looking)': False,\n",
       " 'contains(forward)': False,\n",
       " 'contains(enemy)': False}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_features(['love', 'this', 'car'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our feature extractor, we can apply the features to our classifier using the method apply_features. We pass the feature extractor along with the tweets list defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = nltk.classify.apply_features(extract_features, tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variable ‘training_set’ contains the labeled feature sets. It is a list of tuples which each tuple containing the feature dictionary and the sentiment string for each tweet. The sentiment string is also called ‘label’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({'contains(love)': True, 'contains(this)': True, 'contains(car)': True, 'contains(view)': False, 'contains(amazing)': False, 'contains(feel)': False, 'contains(great)': False, 'contains(morning)': False, 'contains(excited)': False, 'contains(about)': False, 'contains(the)': False, 'contains(concert)': False, 'contains(best)': False, 'contains(friend)': False, 'contains(not)': False, 'contains(like)': False, 'contains(horrible)': False, 'contains(tired)': False, 'contains(looking)': False, 'contains(forward)': False, 'contains(enemy)': False}, 'positive'), ({'contains(love)': False, 'contains(this)': True, 'contains(car)': False, 'contains(view)': True, 'contains(amazing)': True, 'contains(feel)': False, 'contains(great)': False, 'contains(morning)': False, 'contains(excited)': False, 'contains(about)': False, 'contains(the)': False, 'contains(concert)': False, 'contains(best)': False, 'contains(friend)': False, 'contains(not)': False, 'contains(like)': False, 'contains(horrible)': False, 'contains(tired)': False, 'contains(looking)': False, 'contains(forward)': False, 'contains(enemy)': False}, 'positive'), ...]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our training set, we can train our classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(training_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Naive Bayes classifier uses the prior probability of each label which is the frequency of each label in the training set, and the contribution from each feature. In our case, the frequency of each label is the same for ‘positive’ and ‘negative’. The word ‘amazing’ appears in 1 of 5 of the positive tweets and none of the negative tweets. This means that the likelihood of the ‘positive’ label will be multiplied by 0.2 when this word is seen as part of the input.\n",
    "\n",
    "Let’s take a look inside the classifier train method in the source code of the NLTK library. ‘label_probdist’ is the prior probability of each label and ‘feature_probdist’ is the feature/value probability dictionary. Those two probability objects are used to create the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.probability import ELEProbDist, FreqDist, DictionaryProbDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(labeled_featuresets, estimator=ELEProbDist):\n",
    "    # Create the P(label) distribution\n",
    "    label_probdist = estimator(label_freqdist)\n",
    "    # Create the P(fval|label, fname) distribution\n",
    "    feature_probdist = {}\n",
    "    return NaiveBayesClassifier(label_probdist, label_freqdist)\n",
    "    label_probdist.prob('positive')\n",
    "    label_probdist.prob('negative')\n",
    "    feature_probdist[('negative', 'contains(best)')].prob(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our case, the probability of each label is 0.5 as we can see below. label_probdist is of type ELEProbDist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
